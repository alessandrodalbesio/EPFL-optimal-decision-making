{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e1b8226-d240-4f07-aa0f-698443cf046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88d73690-5b49-4133-9bf6-9270e9263006",
   "metadata": {},
   "source": [
    "# 3.1.f Traditional Rock Paper Scissors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d09d666b-dc82-46db-b386-ab706515bc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 -1  1]\n",
      " [ 1  0 -1]\n",
      " [-1  1  0]]\n",
      "Rock = 0, Paper = 1, Scissors = 2\n"
     ]
    }
   ],
   "source": [
    "# payoff matrix of the rock-paper-scissors game\n",
    "\n",
    "M = np.array([[0, -1, 1], [1, 0, -1], [-1, 1, 0]])\n",
    "\n",
    "print(M)\n",
    "print('Rock = 0, Paper = 1, Scissors = 2')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7edbbbe0",
   "metadata": {},
   "source": [
    "#### Assuming that the row-player’s strategy is to play rock with probability 1, derive the best-response strategy of the column-player "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec6ebdbe",
   "metadata": {},
   "source": [
    "(i) logical reasoning : the best response strategy of the column player is to play paper with probability 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "589d0455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best response strategy of the column player is to play *rock* with probability 0.0\n",
      "The best response strategy of the column player is to play *paper* with probability 1.0\n",
      "The best response strategy of the column player is to play *scissors* with probability 0.0\n"
     ]
    }
   ],
   "source": [
    "Rock, Paper, Scissors = 0, 1, 2\n",
    "\n",
    "# (ii) solving a linear program\n",
    "\n",
    "# define the variables\n",
    "x = cp.Variable(3, nonneg=True)\n",
    "\n",
    "# define the objective function\n",
    "obj = cp.Minimize(cp.sum(cp.multiply(M[Rock,:], x)))\n",
    "\n",
    "# define the constraints\n",
    "constraints = [cp.sum(x) == 1]\n",
    "\n",
    "# define the problem\n",
    "prob = cp.Problem(obj, constraints)\n",
    "\n",
    "# solve the problem\n",
    "prob.solve()\n",
    "\n",
    "# print the solution\n",
    "print(f'The best response strategy of the column player is to play *rock* with probability', round(x.value[Rock], 3))\n",
    "print(f'The best response strategy of the column player is to play *paper* with probability', round(x.value[Paper],3))\n",
    "print(f'The best response strategy of the column player is to play *scissors* with probability', round(x.value[Scissors], 3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duality theory can be used to reformulate the given minmax inner minimization problem as a maximization problem.\n",
    "\n",
    "Let's start by defining the Lagrangian function for the given problem as:\n",
    "\n",
    "L(p,λ) = min(q∈∆) p^⊤Mq + λ(1 - ∑ pi)\n",
    "\n",
    "Here, λ is the Lagrange multiplier associated with the constraint that the sum of probabilities is equal to 1.\n",
    "\n",
    "The dual function can be defined as the infimum of the Lagrangian function over the primal variable p:\n",
    "\n",
    "g(λ) = inf(p∈∆) L(p,λ) = inf(p∈∆) (min(q∈∆) p^⊤Mq + λ(1 - ∑ pi))\n",
    "\n",
    "Now, let's consider the maximization problem:\n",
    "\n",
    "maximize(g(λ)) subject to λ≥0\n",
    "\n",
    "The dual problem is to find the optimal value of λ that maximizes the dual function g(λ) subject to the non-negativity constraint on λ.\n",
    "\n",
    "Using the strong duality theorem, we know that the optimal value of the dual problem is equal to the optimal value of the primal problem. Therefore, we can solve the original minmax inner minimization problem by solving the dual problem.\n",
    "\n",
    "To obtain the reformulated problem, we can write the dual function as:\n",
    "\n",
    "g(λ) = inf(p∈∆) (min(q∈∆) p^⊤Mq) + λ(1 - ∑ pi)\n",
    "\n",
    "The first term inside the infimum is a minimum over q, which is a linear function of p. Therefore, we can interchange the order of the minimum and the infimum and obtain:\n",
    "\n",
    "g(λ) = min(q∈∆) (inf(p∈∆) p^⊤Mq + λ(1 - ∑ pi))\n",
    "\n",
    "The term inside the infimum is a linear function of p and can be expressed as:\n",
    "\n",
    "p^⊤Mq + λ(1 - ∑ pi) = (λpi + p^⊤Mq) - λ\n",
    "\n",
    "This is a linear function of pi, and its minimum over pi is achieved at pi = 0 if λM + q ≤ 0, and pi = 1 if λM + q > 0. Therefore, we can express the dual function as:\n",
    "\n",
    "g(λ) = min(q∈∆) max(0, λM + q)\n",
    "\n",
    "This is a maximization problem, where we maximize over q and minimize over λ. Therefore, the reformulated problem is:\n",
    "\n",
    "maximize (q∈∆) max(0, λM + q)\n",
    "\n",
    "This is the maximization problem that is equivalent to the original minmax inner minimization problem using duality theory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cb659f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var1758.T @ [[ 0. -1.  2.]\n",
      " [ 1.  0. -1.]\n",
      " [-1.  1.  0.]].T\n",
      "Status: optimal\n",
      "\n",
      "The best response strategy of the *row* player is to play *rock* with probability [0.25]\n",
      "The best response strategy of the *row* player is to play *paper* with probability [0.417]\n",
      "The best response strategy of the *row* player is to play *scissors* with probability [0.333]\n",
      "\n",
      "\n",
      "The expected payoff of the row player is 0.083\n"
     ]
    }
   ],
   "source": [
    "# construct the Nash strategies of both players and report the expected payoff of the row-player. Interpret your results.\n",
    "\n",
    "# define the variables\n",
    "p = cp.Variable((3,1), nonneg=True)\n",
    "a = cp.Variable((1), nonneg=True)\n",
    "\n",
    "# define the objective function\n",
    "\n",
    "obj = cp.Maximize(a)\n",
    "\n",
    "# define the constraints\n",
    "constraints = [cp.sum(p) == 1, a <= (p.T@M).T]\n",
    "\n",
    "# define the problem\n",
    "prob = cp.Problem(obj, constraints)\n",
    "\n",
    "# solve the problem\n",
    "prob.solve()\n",
    "print(f'Status: {prob.status}\\n')\n",
    "\n",
    "# print the solution\n",
    "print( \"The best response strategy of the *row* player is to play *rock* with probability\", np.round(p.value, 3)[Rock])\n",
    "print( \"The best response strategy of the *row* player is to play *paper* with probability\", np.round(p.value, 3)[Paper])\n",
    "print( \"The best response strategy of the *row* player is to play *scissors* with probability\", np.round(p.value, 3)[Scissors])\n",
    "print('')\n",
    "\n",
    "print(f'\\nThe expected payoff of the row player is', np.round(prob.value, 3))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c9d297d",
   "metadata": {},
   "source": [
    "Let p be a Nash strategy for the row-player in the game represented by the matrix M. Then, for any column strategy q, we have:\n",
    "\n",
    "p^T M q ≤ p^T M p (1)\n",
    "\n",
    "where the inequality follows from the definition of a Nash strategy, which states that the row-player cannot improve her expected payoff by unilaterally changing her strategy.\n",
    "\n",
    "Now, let v be an optimal strategy for the column-player in the game represented by the matrix M, i.e.,\n",
    "\n",
    "v^T M p ≥ v^T M v (2)\n",
    "\n",
    "where the inequality follows from the definition of an optimal strategy for the column-player, which states that the column-player chooses a strategy that maximizes his/her expected payoff against any row strategy.\n",
    "\n",
    "Multiplying (1) by v^T on both sides, we get:\n",
    "\n",
    "v^T p^T M q ≤ v^T p^T M p (3)\n",
    "\n",
    "Using the fact that (2) holds, we can replace v^T M p on the right-hand side of (3) to obtain:\n",
    "\n",
    "v^T p^T M q ≤ v^T M p ≤ v^T M v (4)\n",
    "\n",
    "The left-hand side of (4) is the expected payoff of the row-player when she plays the strategy p against the column strategy q, while the right-hand side is the minimum value of the game represented by the matrix M, i.e., the optimal value of the minimax problem (1). Therefore, we have shown that:\n",
    "\n",
    "v^T p^T M q ≤ v^T M v (5)\n",
    "\n",
    "for any column strategy q and any Nash strategy p of the row-player. In other words, the expected payoff of the row-player when she plays a Nash strategy cannot fall below the optimal value of the minimax problem, irrespective of the column-player's strategy. This result is known as the minimax theorem."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d7e26f7-fd53-4739-86cb-1555d6d8d761",
   "metadata": {},
   "source": [
    "# 2.1.g Modified Rock Paper Scissors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c0c39c63-e495-4364-8f76-93bcdd24d220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payoff matrix of the modified rock-paper-scissors game:\n",
      "\n",
      "[[ 0 -1  2]\n",
      " [ 1  0 -1]\n",
      " [-1  1  0]]\n",
      "Rock = 0, Paper = 1, Scissors = 2\n",
      "\n",
      "Status: optimal\n",
      "The best response strategy of the *row* player is to play *rock* with probability [0.25]\n",
      "The best response strategy of the *row* player is to play *paper* with probability [0.417]\n",
      "The best response strategy of the *row* player is to play *scissors* with probability [0.333]\n",
      "\n",
      "\n",
      "The expected payoff of the row player is 0.083\n"
     ]
    }
   ],
   "source": [
    "# Consider a modified rock-paper-scissors game, where the payoff of the row-player amounts to +2 instead of +1 if she wins by playing rock. \n",
    "\n",
    "# define the modified payoff matrix\n",
    "\n",
    "print(\"Payoff matrix of the modified rock-paper-scissors game:\\n\")\n",
    "M = np.array([[0, -1, 2], [1, 0, -1], [-1, 1, 0]])\n",
    "print(M)\n",
    "print('Rock = 0, Paper = 1, Scissors = 2\\n')\n",
    "\n",
    "# define the variables\n",
    "p = cp.Variable((3,1), nonneg=True)\n",
    "a = cp.Variable((1), nonneg=True)\n",
    "\n",
    "# define the objective function\n",
    "\n",
    "obj = cp.Maximize(a)\n",
    "\n",
    "# define the constraints\n",
    "constraints = [cp.sum(p) == 1, a <= (p.T@M).T]\n",
    "\n",
    "# define the problem\n",
    "prob = cp.Problem(obj, constraints)\n",
    "\n",
    "# solve the problem\n",
    "prob.solve()\n",
    "print(f'Status: {prob.status}')\n",
    "\n",
    "# print the solution\n",
    "print( \"The best response strategy of the *row* player is to play *rock* with probability\", np.round(p.value, 3)[Rock])\n",
    "print( \"The best response strategy of the *row* player is to play *paper* with probability\", np.round(p.value, 3)[Paper])\n",
    "print( \"The best response strategy of the *row* player is to play *scissors* with probability\", np.round(p.value, 3)[Scissors])\n",
    "print('')\n",
    "\n",
    "print(f'\\nThe expected payoff of the row player is', np.round(prob.value, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf94477b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Zero sum game with payoff matrices:\n",
       "\n",
       "Row player:\n",
       "[[ 0 -1  2]\n",
       " [ 1  0 -1]\n",
       " [-1  1  0]]\n",
       "\n",
       "Column player:\n",
       "[[ 0  1 -2]\n",
       " [-1  0  1]\n",
       " [ 1 -1  0]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nashpy as nash\n",
    "import numpy as np\n",
    "\n",
    "A = np.array([[0, -1, 2], [1, 0, -1], [-1, 1, 0]])\n",
    "B = - A\n",
    "rps = nash.Game(A, B)\n",
    "rps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9bf43720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Nash equilibria are:\n",
      "\n",
      "For the row player: rock :  0.25 , paper :  0.417 , scissors :  0.333\n",
      "For the column player: rock :  0.333 , paper :  0.417 , scissors :  0.25\n",
      "the payoff for the row player is :  0.083\n",
      "the payoff for the column player is :  -0.083\n"
     ]
    }
   ],
   "source": [
    "eqs = rps.support_enumeration()\n",
    "\n",
    "eqs = list(eqs)\n",
    "\n",
    "print(\"The Nash equilibria are:\\n\")\n",
    "print(\"For the row player: rock : \", np.round(eqs[0][0][0], 3) ,\", paper : \", np.round(eqs[0][0][1], 3), \", scissors : \", np.round(eqs[0][0][2], 3))\n",
    "print(\"For the column player: rock : \", np.round(eqs[0][1][0], 3) ,\", paper : \", np.round(eqs[0][1][1], 3), \", scissors : \", np.round(eqs[0][1][2], 3))\n",
    "\n",
    "print(\"the payoff for the row player is : \", np.round(eqs[0][0]@A@eqs[0][1].T, 3))\n",
    "print(\"the payoff for the column player is : \", np.round(eqs[0][0]@B@eqs[0][1].T, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6d5b83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
